# Домашнее задание к занятию «Компоненты Kubernetes»

### Цель задания

Рассчитать требования к кластеру под проект

------

### Инструменты и дополнительные материалы, которые пригодятся для выполнения задания:

- [Considerations for large clusters](https://kubernetes.io/docs/setup/best-practices/cluster-large/),
- [Architecting Kubernetes clusters — choosing a worker node size](https://learnk8s.io/kubernetes-node-size).

------

>### Задание. Необходимо определить требуемые ресурсы
>Известно, что проекту нужны база данных, система кеширования, а само приложение состоит из бекенда и фронтенда. Опишите, какие ресурсы нужны, если известно:
>
>1. Необходимо упаковать приложение в чарт для деплоя в разные окружения. 
>2. База данных должна быть отказоустойчивой. Потребляет 4 ГБ ОЗУ в работе, 1 ядро. 3 копии. 
>3. Кеш должен быть отказоустойчивый. Потребляет 4 ГБ ОЗУ в работе, 1 ядро. 3 копии. 
>4. Фронтенд обрабатывает внешние запросы быстро, отдавая статику. Потребляет не более 50 МБ ОЗУ на каждый экземпляр, 0.2 ядра. 5 копий. 
>5. Бекенд потребляет 600 МБ ОЗУ и по 1 ядру на копию. 10 копий.

----
# - РЕШЕНИЕ 

### Важные замечания по конфигурации приложения

- Мы не сможем разнести равномерно 10 реплик Backend например по 3 нодам, получится 4 на одной из нод. И для Frontend по этой-же причине надо принять 2 реплики на ноду, при решении на 3 хоста. 
- Ноды лучше одинаковые - это не обязательно, но так мы уверены в ресурсах, куб разместит podы произвольно. 
- База данных и кеш должны быть отказоустойчивыми. Это минимум 3 реплики, разнесенные по 3 узлам в рабочем режиме.
- Плюс надо принять в расчет накладные на отказ одной ноды, т.е. распределить ресурсы с учетом количества реплик для приложения по оставшимся узлам, в нашем случае в аварином режиме `минимум две ноды - это база для расчета`.
- Общее правило систем на консенсусе для кворума систем хранения - это нечетное количество узлов 3,5,7... В нашем случае меньше хостов в кластере с конфигурацей по мощнее и дороже или больше хостов в кластере но слабее и дешевле. Надо посчитать.
- Нужен запас на пиковые нагрузки, обычно говорят про усредненную цифру в 15-25%, но все зависит от самого приложения и требований (SLO...), может потребоваться и 50% запаса. Нужно мониторить приложение и делать соответствующие масштабирования

### При планировании ресурсов ноды мы используем схему

  #### 1. Ресурсы для OS+Kubelet - это всегда идет в расчет и [по следуущей схеме](https://learnk8s.io/kubernetes-node-size)

  |**Для CPU:**
  |-
  6% от первого ядра.   
  1% следующего ядра (до 2 ядер).   
  0,5% следующих двух ядер (до 4).   
  0,25% любых ядер свыше четырех ядер.   

  |**Для RAM:**
  |-
  255 МБ памяти для машин с объемом памяти менее 1 ГБ. 
  25% от первых 4Гб памяти. 
  20% от следующих 4 ГБ памяти (до 8 ГБ). 
  10% от следующих 8 ГБ памяти (до 16 ГБ). 
  6% от следующих 112Гб памяти (до 128Гб). 
  2% любой памяти выше 128 ГБ.

  #### 2. Ресурсы для DaemonSets

  Это - CNI, kube-proxy, логгер, мониторинг и тп в зависимости от стека  
  И это ≈ 400–1200m CPU и 350–1500Mi RAM  
  Размещаются в `allocatable` (см ниже)

  #### 3. Allocatable - сюда scheduler размещает поды

  До тех пор пока не упрется в `eviction threshold` - порог выселения, обычно составляет 100 МБ. Дальше k8s будет вытеснять поды с ноды в свободные ноды, если они есть.

  #### Выбор размера ноды

  Мы можем разместить приложение на малом количестве мощных нод или на большом количестве слабых нод. Оба подхода требуют расчета и анализа, имеют свои недостатки и преимущества  

  Мощные ноды:
  - Их мало
  - Лучше подходят для тяжелых ресурсоемких и высоконагруженных приложений
  - Быстрее стартуют, не шумят системным трафиком
  - Стоют дороже
  - ...

  Слабые ноды:
  - Их много
  - Создают сильный системный трафик
  - Долго стартуют, грузят image...
  - Стоят дешевле
  - ...

  ### Для упрощения будем ориентироваться на варианты конфигураций VM для наших workers на YC:

  Нам доступны конфигурации с шагом 2 CPU, а вот RAM с шагом кратном CPU, к примеру:

  | N | CPU | RAM GB | Примерная цена руб/мес 
  |---|-----|----|-
  | 1 | 8   | 16 | 10 459
  | 2 | 10  | 20 | 12 963
  | 3 | 12  | 24 | 15 467           
  | 4 | 16  | 64 | 27 442 
  | 5 | 32  | 128| 47 473

  ---

### Т.о. РАСЧЕТ: 

### Расчет на 3 ноды

- Минимально требуется 3 ноды
- В аварийном режиме приложение сможет временно работать на 2-х нодах - надо заложить в расчет этот момент

Прикинем необходимые ресурсы для одной ноды в случае отказа одного узла из 3-х. Т.е. для размещения приложения на 2х узлах.  
Учтем, что для одного нода при требовании для приложения в 5 реплик, на 1 узел считаем 5/2+5%2 = 3 (аварийный случай)   

| `3. Приложение` | CPU/Pod | RAM GB/Pod  | Требуется реплик | Реплик/Node | CPU всего/Node  | RAM GB всего/Node   
| --------- | ------- | -----   |-    | ------ | ---------- |-
| DB        | 1       | 4       | 3+    | 1      | 1          | 4
| Cache     | 1       | 4       | 3+    | 1      | 1          | 4
| Backend   | 1       | 0.6     | 10    | 5      | 5          | 3.5
| Frontend  | 0.2     | 0.05    | 5     | 3      | 0.6        | 0.15
|  |         |         |    |   **Всего**     | **7.6**    | **11.55** 

| `1. OS+Kubelet`  CPU >= 8, RAM >= 12 на Node| f | =
|- |- |-
| CPU | 0.6 + 0.1 + 0.5 + 0.25 | 1.45
| RAM |  25% от первых 4Гб, 20% от следующих 4 ГБ, 10% от следующих 8 ГБ | 2.8 GB

| `2. Ресурсы для DaemonSets возмем среднее` | =
|-|-
| CPU | 0.8
| RAM | 1GB

| Итог | OS+Kubelet + DaemonSets + Pods + 20% | =
|-|-|-
| CPU | 1.45 + 0.8 + 7.6  | 11.82 (`12`)
| RAM | 2.8 + 1 + 11.5 | 18.36 (`24` - Ближайшее значение в YC)

--- 

### Расчет на 5 нод
- В аварийном режиме приложение сможет временно работать на 4-х нодах - надо заложить в расчет этот момент

Прикинем необходимые ресурсы для одной ноды в случае отказа одного узла из 5-ти. Т.е. для размещения приложения на 4х узлах.  
Учтем, что для одного нода при требовании для приложения в 5 реплик, на 1 узел считаем 2 (аварийный случай), 5/4+5%4 -> 2   

| `3. Приложение` | CPU/Pod | RAM GB/Pod  | Требуется реплик | Реплик/Node | CPU всего/Node  | RAM GB всего/Node   
| --------- | ------- | -----   |-    | ------ | ---------- |-
| DB        | 1       | 4       |3+    | 1      | 1          | 4
| Cache     | 1       | 4       |3+    | 1      | 1          | 4
| Backend   | 1       | 0.6     |10    | 3      | 3          | 3.5
| Frontend  | 0.2     | 0.05    |5    | 2      | 0.4        | 0.1
| |         |         |    |     **Всего**    | **5.4**    | **11.6** 

| `1. OS+Kubelet`  CPU >= 6, RAM >= 12 на Node| f | =
|- |- |-
| CPU | 0.6 + 0.1 + 0.5 + 0.25 | 1.45
| RAM |  25% от первых 4Гб, 20% от следующих 4 ГБ, 10% от следующих 8 ГБ | 2.8 GB

| `2. Ресурсы для DaemonSets возмем среднее` | =
|-|-
| CPU | 0.8
| RAM | 1GB

| Итог | OS+Kubelet + DaemonSets + Pods + 20% | =
|-|-|-
| CPU | (1.45 + 0.8 + 5.4)+20%  | 9.18 (`10`)
| RAM | (2.8 + 1 + 11.6)+20% | 18.48 (`20` - Ближайшее значение в YC)

### Итог

- Выбор решения на 3 ноды 12CPU/24RAM = 15 467 * 3 = 46 401 р/мес соответствует заданию.
- Вариант например 5 x 10CPU/20RAM = 12 963 * 5 = 64 815 р/мес уже дороже на 19%, но имеет преимущество по устойчивости к отказу 1 нод, выдержит отказ 2х нод, но в этом случае пиковые нагрузки могут привести к перегрузке.



