# Домашнее задание к занятию 17 «Инцидент-менеджмент»

    ## Задание

    Составьте постмортем на основе реального сбоя системы GitHub в 2018 году.

    Информацию о сбое можно изучить по ссылкам ниже:

    * [краткое описание на русском языке](https://habr.com/ru/post/427301/);
    * [развёрнутое описание на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).****


---


# Постмортем инцидента, затронувшего сервисы GitHub 21 и 22 октября.

## Краткое описание инцидента

В воскресенье, в 22:52 по UTC, несколько сервисов на GitHub.com пострадали из-за разрыва сети и последующего сбоя базы данных. Связь была восстановлена ​​за 43 секунды, но этот кратковременный сбой спровоцировал цепочку событий, которые привели к снижению качества обслуживания в течение 24 часов и 11 минут. Хотя некоторые части нашей платформы не пострадали от этого инцидента, несколько внутренних систем были затронуты, что привело к отображению устаревшей и противоречивой информации.


## Предшествующие события

В 22:52 UTC 21 октября плановые работы по замене вышедшего из строя оптического оборудования 100G привели к потере связи между нашим сетевым узлом на восточном побережье США и нашим основным центром обработки данных на восточном побережье США на 43 секунды.

## Причина инцидента

На серверах баз данных в центре на восточном побережье в течение короткого периода времени хранились записи, которые не были реплицированы на сервер на западном побережье. Нам не удалось безопасно переключить основной сервер обратно на центр обработки данных на восточном побережье.

## Воздействие

Все это привело к отображению устаревшей и противоречивой информации. В течение большей части инцидента GitHub также не мог обрабатывать события веб-перехватов, а также создавать и публиковать сайты GitHub Pages.  
Общее количество записей, не реплицированных на западное побережье, было относительно небольшим. Например, в одном из наших самых загруженных кластеров в пострадавшем окне было 954 записи.

## Обнаружение

21 октября 2018 г. 22:54 наши внутренние системы мониторинга начали генерировать оповещения о многочисленных сбоях в работе систем. В это время несколько инженеров работали над сортировкой входящих уведомлений. К 23:02 UTC инженеры нашей группы быстрого реагирования определили, что топологии многочисленных кластеров баз данных находятся в непредвиденном состоянии.

## Реакция

Работоспособность сервисов была востановлена специалистами GitHub за 24 часов и 11 минут.

## Восстановление

Было произведено востановление кластеров из резервных копий, восстановление топологии репликации

## Таймлайн

- 2018 Октября 21 22:52 UTC

    Запуск оркестратором смены лидера БД и перенос трафика записи на новые основные узлы на площадке западного побережья. 

- 2018 Октября 21 22:54 UTC

    К 23:02 UTC инженеры нашей группы быстрого реагирования определили, что топологии многочисленных кластеров баз данных находятся в непредвиденном состоянии

- 2018 Октября 21 23:07 UTC

    Решение о блокировке внутренних инструментов развертывания, для предотвращения дополнительных изменений.  
    В 23:09 UTC команда реагирования перевела сайт в жёлтый статус  
    В 23:11 UTC координатор инцидента принял решение изменить статус на красный

- 2018 Октября 21 23:13 UTC

    Накопление несогласованности данных  
    Рост задержки доступа к БД в ДЦ на западном побережье

- 2018 Октября 21 23:19 UTC

    Принято осознанное решение частично снизить удобство использования сайта, приостановив доставку вебхуков и сборку GitHub Pages

- 2018 Октября 22 00:05 UTC

    Принято решение и запущен длительный процесс восстановления данных из резервных копий, синхронизация реплик на обоих сайтах, возврат к стабильной топологии обслуживания и возобновление обработки заданий в очереди

- 2018 Октября 22 00:41 UTC

    Был запущен процесс резервного копирования всех затронутых кластеров MySQL.  
    Поиск способов ускорить перенос и восстановление данных.

- 2018 Октября 22 06:51 UTC

    Часть кластеров завершили восстановление из резервных копий в нашем центре обработки данных на восточном побережье и начали репликацию новых данных с западного побережья.

- 2018 Октября 22 07:46 UTC

    GitHub опубликовал пост в блоге, чтобы предоставить более подробную информацию о ситуации

- 2018 Октября 22 11:12 UTC

    Все основные серверы баз данных снова установлены на Восточном побережье США. Скорость возросла но пользователи видели несогласованные данные при взаимодействии с нашими сервисом.

- 2018 Октября 22 13:15 UTC

    К этому моменту мы приближались к пиковой нагрузке на GitHub.com.

- 2018 Октября 22 16:24 UTC

    Аварийное переключение на исходную топологию, статус сервиса оставлен красным.

- 2018 Октября 22 16:45 UTC

    Мы оставались в ухудшенном состоянии до тех пор, пока не завершили обработку всех накопившихся данных и не убедились, что наши сервисы явно вернулись к нормальному уровню производительности

- 2018 Октября 22 23:03 UTC

Все ожидаемые вебхуки и сборки страниц были обработаны, целостность и корректная работа всех систем подтверждены. Статус сайта был обновлён до зелёного.

## Последующие действия

Во время восстановления мы собрали двоичные журналы MySQL, содержащие записи, выполненные на нашем основном сайте, которые не были реплицированы на сайт на западном побережье с каждого пострадавшего кластера. В настоящее время мы анализируем эти журналы и определяем, какие записи можно автоматически синхронизировать, а какие потребуют обращения к пользователям.

Мы запустили общекорпоративную инженерную инициативу по поддержке обслуживания трафика GitHub из нескольких центров обработки данных в архитектуре «активный/активный/активный». Цель этого проекта — обеспечить резервирование по схеме N+1 на уровне объекта. Цель этой работы — обеспечить устойчивость к полному отказу одного центра обработки данных без ущерба для пользователей.
